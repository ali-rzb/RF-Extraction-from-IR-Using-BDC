{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Please provide a TPU Name to connect to.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Uni\\Project\\Main\\Train_normal.ipynb Cell 1\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Uni/Project/Main/Train_normal.ipynb#W0sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m Sequential\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Uni/Project/Main/Train_normal.ipynb#W0sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mFunctions\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mLocalDB\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mdb\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Uni/Project/Main/Train_normal.ipynb#W0sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mFunctions\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mCNN\u001b[39;00m \u001b[39mimport\u001b[39;00m CNN\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Uni/Project/Main/Train_normal.ipynb#W0sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mFunctions\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mDataUtils\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39md_utils\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Uni/Project/Main/Train_normal.ipynb#W0sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mFunctions\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mGlobalUtils\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mg_utils\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Uni\\Project\\Main\\Functions\\CNN.py:46\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcm\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mcm\u001b[39;00m\n\u001b[0;32m     45\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 46\u001b[0m   tpu \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mdistribute\u001b[39m.\u001b[39;49mcluster_resolver\u001b[39m.\u001b[39;49mTPUClusterResolver()  \u001b[39m# TPU detection\u001b[39;00m\n\u001b[0;32m     47\u001b[0m   \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mRunning on TPU \u001b[39m\u001b[39m'\u001b[39m, tpu\u001b[39m.\u001b[39mcluster_spec()\u001b[39m.\u001b[39mas_dict()[\u001b[39m'\u001b[39m\u001b[39mworker\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m     48\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Program Files\\Python310\\lib\\site-packages\\tensorflow\\python\\distribute\\cluster_resolver\\tpu\\tpu_cluster_resolver.py:198\u001b[0m, in \u001b[0;36mTPUClusterResolver.__init__\u001b[1;34m(self, tpu, zone, project, job_name, coordinator_name, coordinator_address, credentials, service, discovery_url)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[39m\"\"\"Creates a new TPUClusterResolver object.\u001b[39;00m\n\u001b[0;32m    156\u001b[0m \n\u001b[0;32m    157\u001b[0m \u001b[39mThe ClusterResolver will then use the parameters to query the Cloud TPU APIs\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    193\u001b[0m \u001b[39m    Google Cloud environment.\u001b[39;00m\n\u001b[0;32m    194\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    196\u001b[0m \u001b[39mif\u001b[39;00m tpu \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mlocal\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    197\u001b[0m   \u001b[39m# Default Cloud environment\u001b[39;00m\n\u001b[1;32m--> 198\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cloud_tpu_client \u001b[39m=\u001b[39m client\u001b[39m.\u001b[39;49mClient(\n\u001b[0;32m    199\u001b[0m       tpu\u001b[39m=\u001b[39;49mtpu,\n\u001b[0;32m    200\u001b[0m       zone\u001b[39m=\u001b[39;49mzone,\n\u001b[0;32m    201\u001b[0m       project\u001b[39m=\u001b[39;49mproject,\n\u001b[0;32m    202\u001b[0m       credentials\u001b[39m=\u001b[39;49mcredentials,\n\u001b[0;32m    203\u001b[0m       service\u001b[39m=\u001b[39;49mservice,\n\u001b[0;32m    204\u001b[0m       discovery_url\u001b[39m=\u001b[39;49mdiscovery_url)\n\u001b[0;32m    205\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tpu \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cloud_tpu_client\u001b[39m.\u001b[39mname()\n\u001b[0;32m    206\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    207\u001b[0m   \u001b[39m# Directly connected TPU environment\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Program Files\\Python310\\lib\\site-packages\\tensorflow\\python\\tpu\\client\\client.py:142\u001b[0m, in \u001b[0;36mClient.__init__\u001b[1;34m(self, tpu, zone, project, credentials, service, discovery_url)\u001b[0m\n\u001b[0;32m    139\u001b[0m tpu \u001b[39m=\u001b[39m _get_tpu_name(tpu)\n\u001b[0;32m    141\u001b[0m \u001b[39mif\u001b[39;00m tpu \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 142\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mPlease provide a TPU Name to connect to.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    144\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tpu \u001b[39m=\u001b[39m _as_text(tpu)\n\u001b[0;32m    146\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_use_api \u001b[39m=\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tpu\u001b[39m.\u001b[39mstartswith(\u001b[39m'\u001b[39m\u001b[39mgrpc://\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Please provide a TPU Name to connect to."
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense, Flatten\n",
    "from keras import Sequential\n",
    "import Functions.LocalDB as db\n",
    "from Functions.CNN import CNN\n",
    "import Functions.DataUtils as d_utils\n",
    "import Functions.GlobalUtils as g_utils\n",
    "from keras.applications.efficientnet import EfficientNetB0\n",
    "from keras.applications.resnet import ResNet50\n",
    "from keras.applications.densenet import DenseNet121\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.mobilenet_v2 import MobileNetV2\n",
    "from keras.applications.vgg16 import VGG16\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_tale = 1\n",
    "augment_ratio = 0\n",
    "batch_size = 32\n",
    "stp_patience = 10\n",
    "class_num = 10\n",
    "epochs = 100\n",
    "folds = 5\n",
    "\n",
    "models = [DenseNet121]\n",
    "for arch in models:\n",
    "    try: os.mkdir(f'models/{arch.__name__}') \n",
    "    except: pass\n",
    "\n",
    "cnn = CNN(class_num=class_num, frame_tale=frame_tale, augment_ratio=augment_ratio, batch_size=batch_size, \n",
    "            early_stopping_patience=stp_patience, resize_images=(75, 75))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.prepare_data(shuffle_frames=True, color_mode='rgb', k_fold=folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import DATA_INFO as di\n",
    "import Functions.VideoUtils as v_utils\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "import shutil\n",
    "data_path = di.Labeled.path + di.Labeled.FileNames.Folder_Name.format(1, 10, 20, 0)\n",
    "frames_info = shuffle(db.get_db(data_path + \"/frames_info.txt\", v_utils.frame_info))\n",
    "test_video_indexes = [1, 7, 13]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_list = list(f.flow for f in frames_info)\n",
    "class_num = 10\n",
    "class_borders = [-1]\n",
    "step = (max(flow_list) - min(flow_list)) / class_num\n",
    "class_borders = class_borders + list(np.arange(min(flow_list), max(flow_list) + step, step))[1:]\n",
    "\n",
    "save_path = di.Labeled.path + \"Normal_Labeling_C10\" + '/'\n",
    "# Making Folders\n",
    "if not os.path.isdir(save_path):\n",
    "    os.mkdir(save_path)\n",
    "d_utils.clear_folder_content(save_path)\n",
    "os.mkdir(save_path + 'train')\n",
    "os.mkdir(save_path + 'test')\n",
    "os.mkdir(save_path + 'val')\n",
    "for i in range(class_num):\n",
    "    for mode in ['train', 'test', 'val']:\n",
    "        _path = f'{save_path}{mode}/{i}'\n",
    "        if not os.path.isdir(_path):\n",
    "            os.mkdir(_path)\n",
    "            d_utils.clear_folder_content(_path)              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pBar = g_utils.ProgressBar(len(frames_info), 0, True)\n",
    "for frame in frames_info:\n",
    "    frame_type = 'train'\n",
    "    if v_utils.frame_info.cast(frame).video_number in test_video_indexes:\n",
    "        frame_type = 'test'\n",
    "    _class = d_utils.get_class_custom_borders(frame.flow, class_borders)\n",
    "    shutil.copyfile(f\"{data_path}/backup/{frame.class_number}/{frame.image_name}\", f\"{save_path}/{frame_type}/{_class}/{frame.image_name}\")\n",
    "    pBar.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 17 image(s) found.\n",
      "Output directory set to Data/3_Labeled/Normal_Labeling_C10/train/0/."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=L size=75x75 at 0x26D1713C730>: 100%|██████████| 1441/1441 [00:08<00:00, 169.55 Samples/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 125 image(s) found.\n",
      "Output directory set to Data/3_Labeled/Normal_Labeling_C10/train/1/."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=L size=75x75 at 0x26D170565F0>: 100%|██████████| 1333/1333 [00:07<00:00, 169.57 Samples/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 340 image(s) found.\n",
      "Output directory set to Data/3_Labeled/Normal_Labeling_C10/train/2/."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=L size=75x75 at 0x26D159B9DB0>: 100%|██████████| 1118/1118 [00:06<00:00, 169.83 Samples/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 546 image(s) found.\n",
      "Output directory set to Data/3_Labeled/Normal_Labeling_C10/train/3/."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=L size=75x75 at 0x26D170DDA80>: 100%|██████████| 912/912 [00:04<00:00, 186.50 Samples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 721 image(s) found.\n",
      "Output directory set to Data/3_Labeled/Normal_Labeling_C10/train/5/."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=L size=75x75 at 0x26D159BB9A0>: 100%|██████████| 737/737 [00:03<00:00, 184.57 Samples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 361 image(s) found.\n",
      "Output directory set to Data/3_Labeled/Normal_Labeling_C10/train/6/."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=L size=75x75 at 0x26D17037AF0>: 100%|██████████| 1097/1097 [00:05<00:00, 183.28 Samples/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 302 image(s) found.\n",
      "Output directory set to Data/3_Labeled/Normal_Labeling_C10/train/7/."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=L size=75x75 at 0x26D17160D60>: 100%|██████████| 1156/1156 [00:06<00:00, 190.60 Samples/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 104 image(s) found.\n",
      "Output directory set to Data/3_Labeled/Normal_Labeling_C10/train/8/."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=L size=75x75 at 0x26D170AF3D0>: 100%|██████████| 1354/1354 [00:07<00:00, 181.45 Samples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 101 image(s) found.\n",
      "Output directory set to Data/3_Labeled/Normal_Labeling_C10/train/9/."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=L size=75x75 at 0x26D1538ACB0>: 100%|██████████| 1357/1357 [00:09<00:00, 150.21 Samples/s]\n"
     ]
    }
   ],
   "source": [
    "d_utils.Equalize_Classes(folder_name= f\"Normal_Labeling_C10/train\", class_num=class_num, Aug_ratio=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Flatten\n",
    "from keras import Sequential\n",
    "import Functions.LocalDB as db\n",
    "from Functions.CNN import CNN\n",
    "import Functions.DataUtils as d_utils\n",
    "from keras.applications.efficientnet import EfficientNetB0\n",
    "from keras.applications.resnet import ResNet50\n",
    "from keras.applications.densenet import DenseNet121\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.mobilenet_v2 import MobileNetV2\n",
    "from keras.applications.vgg16 import VGG16\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "frame_tale = 1\n",
    "augment_ratio = 5\n",
    "batch_size = 32\n",
    "stp_patience = 10\n",
    "class_num = 10\n",
    "epochs = 100\n",
    "folds = 5\n",
    "\n",
    "\n",
    "models = [DenseNet121]\n",
    "for arch in models:\n",
    "    try:\n",
    "        os.mkdir(f'models/{arch.__name__}')\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "cnn = CNN(class_num=class_num, frame_tale=frame_tale, augment_ratio=augment_ratio, batch_size=batch_size, \n",
    "            early_stopping_patience=stp_patience, resize_images=(75, 75))\n",
    "cnn.dataset_path = save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Epoch 1/100\n"
     ]
    }
   ],
   "source": [
    "path = f'models/normal_{arch.__name__}'\n",
    "cnn.model = Sequential()\n",
    "cnn.model.add(arch(include_top=False, input_shape=(cnn.image_size[0], cnn.image_size[1], 3), classes=class_num, weights=None))\n",
    "cnn.model.add(Flatten())\n",
    "cnn.model.add(Dense(64, activation='relu'))\n",
    "cnn.model.add(Dense(class_num, activation='softmax'))\n",
    "\n",
    "cnn.history = CNN.hist(model_info=f'Fnull_C{class_num:02d}_{arch.__name__}')\n",
    "cnn.train_model(epochs=epochs, save_model_path=path)\n",
    "db.insert(f'{path}/log.txt', cnn.history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
